{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgUukt-NWmGm"
   },
   "source": [
    "<h1>Kaggle Competition: Spooky Author Identification</h1>\n",
    "(https://www.kaggle.com/c/spooky-author-identification)\n",
    "\n",
    "This notebook ultimately assigns snippets of books to one of three authors.\n",
    "\n",
    "It does so thanks to having learnt these writers' style and vocabulary via Deep Learning techniques.\n",
    "\n",
    "In this notebook, we explore three different techniques:\n",
    "\n",
    "1) Recurrent Neural Network with LSTM and a single embedding layer.\n",
    "\n",
    "2) The same as 1) but with an additional 1D convolutional layer \n",
    "\n",
    "3) The same as 2) but with pre-trained glove 300 dimension word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uBoHSjIVPT9"
   },
   "source": [
    "Put together only thanks to:\n",
    "\n",
    "\n",
    "*   https://github.com/msahamed/yelp_comments_classification_nlp\n",
    "*   http://nbviewer.jupyter.org/github/SDS-AAU/M3-2018/blob/master/notebooks/Hatespeech_LSTM_SDS.ipynb?fbclid=IwAR3yEslQ96DPfy4sBm3ABxYtP4X8xoh-RKBuzhE5ZfKb757Mp9XjD36oIyQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PfupsK19r1Ek",
    "outputId": "3309a45c-ebdd-422b-9424-dc8634b6111f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/janpetr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Embedding\n",
    "#from keras.layers.embeddings import Embedding\n",
    "\n",
    "# Plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "import matplotlib as plt\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Others\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVMDnf5eUZln"
   },
   "source": [
    "Firstly, we need to download necessary files. It's a bit more complicated than with a simple Anaconda Python notebook, but still okay.\n",
    "\n",
    "1) Training dataset\n",
    "\n",
    "2) Testing dataset\n",
    "\n",
    "3) Glove pre-trained words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "ZXziuDhEGUe9",
    "outputId": "c2633566-252b-4261-c1b1-b6a50c65a598"
   },
   "source": [
    "# 1) Training dataset\n",
    "!wget https://raw.githubusercontent.com/SDS-AAU/M3-2018/master/assignments/individual/data/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "o0ZmSnOCeLsq",
    "outputId": "a1ffe556-6ff2-459b-979f-f1bd4957a278"
   },
   "source": [
    "# 2) Testing dataset\n",
    " !wget https://raw.githubusercontent.com/SDS-AAU/M3-2018/master/assignments/individual/data/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "#url = 'https://raw.githubusercontent.com/SDS-AAU/M3-2018/master/assignments/individual/data/train.csv'\n",
    "#r = requests.get(url)\n",
    "\n",
    "with open('train.csv', 'wb') as train:\n",
    "    train.write(r.content)\n",
    "\n",
    "print(\"File downloaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "#url = 'https://raw.githubusercontent.com/SDS-AAU/M3-2018/master/assignments/individual/data/test.csv'\n",
    "#r = requests.get(url)\n",
    "\n",
    "with open('test.csv', 'wb') as test:\n",
    "    test.write(r.content)\n",
    "\n",
    "print(\"File downloaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "_5CcXv0m8wI2",
    "outputId": "3ba07a5a-d396-487a-fabf-1aed3c1b5d55"
   },
   "source": [
    "# 3) Glove pre-trainned packages of words\n",
    " !wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if r.status_code == 200:\n",
    "    # Use io.BytesIO for the zip file content in memory\n",
    "    zip_ref = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    # Extract the content of the zip file in the current directory\n",
    "    zip_ref.extractall('.')\n",
    "    # Close the ZipFile object\n",
    "    zip_ref.close()\n",
    "    print(\"Files extracted successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the file. Status code:\", r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fucmhJD0VBgr"
   },
   "source": [
    "Let's see how the datasets look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "osGa9AWosLYe",
    "outputId": "3691ad3d-e866-4d57-dc5c-cecddfd98ec8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "zqy4cjJJX1Eg",
    "outputId": "702db2bb-ca16-4c02-909f-05a241e88a87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>author_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "   author_label  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             2  \n",
       "4             1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"author\"] = df[\"author\"].astype('category')\n",
    "df[\"author_label\"] = df[\"author\"].cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBAFT-YL1ILX"
   },
   "source": [
    "*   EAP 0\n",
    "*   HPL 1\n",
    "*  MWS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "LlVRych4VmYn",
    "outputId": "9e560994-d75d-40b1-f59e-c9b0f13e19b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8KSTXEcvPvK"
   },
   "source": [
    "Let's do a bit of language preprocessing. Looking at the results with and without this step, though, language preprocessing actually decreases the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lTzb8KziEkK"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    text = text.split()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujhT02dXiGUB"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: clean_text(x))\n",
    "df_test['text'] = df_test['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "er1JPR0xjt-e",
    "outputId": "09c69b55-f23b-4698-a5cb-93e6c709976f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    process howev afford mean ascertain dimens dun...\n",
       "1                  never occur fumbl might mere mistak\n",
       "2    left hand gold snuff box which caper hill cut ...\n",
       "3    love spring look windsor terrac sixteen fertil...\n",
       "4    find noth els even gold superintend abandon at...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "LDux8_4ij5dE",
    "outputId": "7c25e246-08e7-4737-f785-6e27413fee4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    still urg leav ireland inquietud impati father...\n",
       "1    fire want fan could readili fan newspap govern...\n",
       "2    broken frail door found this : two clean pick ...\n",
       "3    think possibl manag without them one actual tu...\n",
       "4                       sure limit knowledg may extend\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIjj5pldvwhm"
   },
   "source": [
    "Creating the type of dataset the Deep Learning models work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgF730PGuLxT"
   },
   "outputs": [],
   "source": [
    "### Create sequence\n",
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "data = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "nE9v0oneaKs2",
    "outputId": "07bcdc39-1e3b-4dba-f5a6-f8bdfd17331e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  3276,    15,   156],\n",
       "       [    0,     0,     0, ...,    17,   168,  1850],\n",
       "       [    0,     0,     0, ...,   219,   521,  2573],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    25,   469, 10248],\n",
       "       [    0,     0,     0, ...,  1782,  6748,   341],\n",
       "       [    0,     0,     0, ...,  1562,   511,  4130]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEiTJTYRUgzu"
   },
   "outputs": [],
   "source": [
    "### Create sequence\n",
    "vocabulary_size =  20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df_test['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df_test['text'])\n",
    "data_test = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "wZ9QZlhzaMDF",
    "outputId": "6bd8678d-95e6-4a7a-9b8d-f3b3e02841f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    17,   513,  1020],\n",
       "       [    0,     0,     0, ...,  1509,  1595,  3862],\n",
       "       [    0,     0,     0, ...,  1685,  2348,   854],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   598,   202,   302],\n",
       "       [    0,     0,     0, ...,  1874,   380, 11823],\n",
       "       [    0,     0,     0, ...,   317,   106,  1350]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_OJVdXXpvon"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPkBKdfhwyuT"
   },
   "source": [
    "We would like to see how the models are doing before blindly classifying the books snippets, right?\n",
    "\n",
    "Let's do some 80/20 K-Fold on the training set beforehand then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NHXI6eizAke"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, df[\"author_label\"], test_size=0.2, random_state=0)\n",
    "\n",
    "labels_train = keras.utils.to_categorical(y_train, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12IOfrHE8eiP"
   },
   "source": [
    "# Long short-term memory (RNN model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WcZOiZB6xpHn"
   },
   "source": [
    "Building the model and training the 80/20 data on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "QmpPbbbWuRBN",
    "outputId": "84215cc3-bce5-4c56-ec67-eb784086aa0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "294/294 [==============================] - 16s 51ms/step - loss: 0.7510 - accuracy: 0.6618 - val_loss: 0.5285 - val_accuracy: 0.7874\n",
      "Epoch 2/3\n",
      "294/294 [==============================] - 16s 55ms/step - loss: 0.2997 - accuracy: 0.8863 - val_loss: 0.5326 - val_accuracy: 0.7917\n",
      "Epoch 3/3\n",
      "294/294 [==============================] - 15s 50ms/step - loss: 0.1599 - accuracy: 0.9438 - val_loss: 0.6201 - val_accuracy: 0.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2880fac90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Network architecture\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(20000, 100, input_length=50))\n",
    "model_lstm.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(3, activation='sigmoid'))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "## Fit the model\n",
    "model_lstm.fit(X_train, labels_train, validation_split=0.4, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pdOMsPhO3aYK",
    "outputId": "ad2c77f1-17b1-4688-a186-ebd20c37841f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/490 [==============================] - 4s 8ms/step - loss: 0.2933 - accuracy: 0.9010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2933073043823242, 0.900976836681366]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.evaluate(X_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRRvYQTXyhGG"
   },
   "source": [
    "Let's see how accurate the model is when predicting the authors within the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "6i3Tq_gxUBX1",
    "outputId": "85845544-a198-4007-a4d8-a1a8e1a2c272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1600\n",
      "           1       0.81      0.77      0.79      1102\n",
      "           2       0.78      0.80      0.79      1214\n",
      "\n",
      "    accuracy                           0.80      3916\n",
      "   macro avg       0.80      0.80      0.80      3916\n",
      "weighted avg       0.80      0.80      0.80      3916\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1308</td>\n",
       "      <td>126</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>846</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>67</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1    2\n",
       "author_label                \n",
       "0             1308  126  166\n",
       "1              151  846  105\n",
       "2              173   67  974"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_lstm.predict(X_test)\n",
    "\n",
    "cr_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, cr_pred))\n",
    "\n",
    "pd.crosstab(y_test,cr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cyoR_VBzwJT"
   },
   "source": [
    "80% is not a bad result IMO. You can the guessed values in the crosstab. \n",
    "\n",
    "The y-axis represents actual values while the x-axis shows the guessed values.\n",
    "\n",
    "Edgar Allan Poe was correctly guessed 75% (1199/1600) of the time.\n",
    "H.P. Lovecraft sees a better accuracy with 78% (864/1102) while Mary Wollstonecraft Shelley was classified correctly most of the time - 80% (978/1214)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Y9uhFLMc2uyn",
    "outputId": "657a18ec-345e-4a71-a75f-bc473cac35b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "368/368 [==============================] - 19s 50ms/step - loss: 0.3343 - accuracy: 0.8783 - val_loss: 0.3318 - val_accuracy: 0.8777\n",
      "Epoch 2/3\n",
      "368/368 [==============================] - 20s 54ms/step - loss: 0.1570 - accuracy: 0.9453 - val_loss: 0.4144 - val_accuracy: 0.8593\n",
      "Epoch 3/3\n",
      "368/368 [==============================] - 18s 49ms/step - loss: 0.0927 - accuracy: 0.9678 - val_loss: 0.5356 - val_accuracy: 0.8473\n",
      "263/263 [==============================] - 2s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "labels = keras.utils.to_categorical(df['author_label'], num_classes=3)\n",
    "\n",
    "model_lstm.fit(data, labels, validation_split=0.4, epochs=3)\n",
    "\n",
    "y_pred = model_lstm.predict(data_test)\n",
    "\n",
    "cr_pred = np.argmax(y_pred, axis=1) # gives a list of predicted values (picks the one with the highest probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "66eUypnIuR6b"
   },
   "source": [
    "Saving the file in the desired format for submission / uploading to the Kaggle competition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "P8D8dcAq4yee",
    "outputId": "c1392ac5-7bc7-4262-b55a-5c5e98836569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        EAP       HPL       MWS       id\n",
      "0  0.665064  0.165110  0.716942  id02310\n",
      "1  0.730497  0.465806  0.337229  id24541\n",
      "2  0.914970  0.273127  0.177266  id00134\n",
      "3  0.871512  0.071910  0.795108  id27757\n",
      "4  0.444277  0.008854  0.991362  id04081\n"
     ]
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df['id'] = df_test['id']\n",
    "y_pred_df.rename(columns={0:'EAP',\n",
    "                          1:'HPL',\n",
    "                          2:'MWS'}, \n",
    "                 inplace=True)\n",
    "print(y_pred_df.head())\n",
    "y_pred_df.to_csv(\"lstm_result.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Jk7C1Dm8nK1"
   },
   "source": [
    "# Long short-term memory + Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sEv3cMjnwGor"
   },
   "source": [
    "In this architecture, we take the previous model and add one Convolutional Layer which is usually used for image processing. This way, the model works slightly faster, although, seemingly at the expense of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdVH-k3d3eiw"
   },
   "outputs": [],
   "source": [
    "def create_conv_model():\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(Embedding(vocabulary_size, 100, input_length=50))\n",
    "    model_conv.add(Dropout(0.2))\n",
    "    model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(LSTM(100))\n",
    "    model_conv.add(Dense(3, activation='sigmoid'))\n",
    "    model_conv.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "    return model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "lStbF5aL3oQx",
    "outputId": "539153de-9290-4253-bb78-bd74cc3cbc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "294/294 [==============================] - 5s 14ms/step - loss: 0.5178 - accuracy: 0.5756 - val_loss: 0.3809 - val_accuracy: 0.7348\n",
      "Epoch 2/3\n",
      "294/294 [==============================] - 4s 14ms/step - loss: 0.2582 - accuracy: 0.8349 - val_loss: 0.3627 - val_accuracy: 0.7558\n",
      "Epoch 3/3\n",
      "294/294 [==============================] - 4s 14ms/step - loss: 0.1471 - accuracy: 0.9105 - val_loss: 0.4173 - val_accuracy: 0.7579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1781f7510>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv = create_conv_model()\n",
    "model_conv.fit(X_train, labels_train, validation_split=0.4, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "LGQnPwfZ5Gc1",
    "outputId": "8cd4e670-ddbc-4c50-fde7-8390a728d70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.79      0.77      1600\n",
      "          1       0.75      0.75      0.75      1102\n",
      "          2       0.76      0.70      0.73      1214\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3916\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1260</td>\n",
       "      <td>161</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187</td>\n",
       "      <td>832</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241</td>\n",
       "      <td>121</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1    2\n",
       "author_label                \n",
       "0             1260  161  179\n",
       "1              187  832   83\n",
       "2              241  121  852"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_conv.predict(X_test)\n",
    "\n",
    "cr_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, cr_pred))\n",
    "\n",
    "pd.crosstab(y_test,cr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_s08vHxJyX9W"
   },
   "source": [
    "Given the fact that we actually expanded the initial architecture, the decrease in accuracy is not so satisfying.\n",
    "\n",
    "Edgar Allan Poe was correctly guessed 81% (1290/1600) of the time.\n",
    "H.P. Lovecraft receives a worse accuracy with 74% (813/1102) while Mary Wollstonecraft Shelley was classified correctly 72% (876/1214)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "74NGruHx8NvP",
    "outputId": "61a8a3d2-5796-433a-8396-889c9ade7a65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "368/368 [==============================] - 5s 13ms/step - loss: 0.2458 - accuracy: 0.8476 - val_loss: 0.2387 - val_accuracy: 0.8477\n",
      "Epoch 2/3\n",
      "368/368 [==============================] - 5s 12ms/step - loss: 0.1308 - accuracy: 0.9224 - val_loss: 0.2871 - val_accuracy: 0.8304\n",
      "Epoch 3/3\n",
      "368/368 [==============================] - 5s 12ms/step - loss: 0.0834 - accuracy: 0.9518 - val_loss: 0.3272 - val_accuracy: 0.8295\n",
      "263/263 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "labels = keras.utils.to_categorical(df['author_label'], num_classes=3)\n",
    "\n",
    "model_conv.fit(data, labels, validation_split=0.4, epochs=3)\n",
    "\n",
    "y_pred = model_conv.predict(data_test)\n",
    "\n",
    "cr_pred = np.argmax(y_pred, axis=1) # gives a list of predicted values (picks the one with the highest probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qwu_HuUOz_3a"
   },
   "source": [
    "Saving the file in the desired format for submission / uploading to the Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "48niuemeBOkT",
    "outputId": "ca51a4df-f9fe-478c-acc1-d3d08ff906a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        EAP       HPL       MWS       id\n",
      "0  0.042708  0.955861  0.008144  id02310\n",
      "1  0.687001  0.206237  0.021206  id24541\n",
      "2  0.111675  0.860745  0.005154  id00134\n",
      "3  0.468072  0.001704  0.583217  id27757\n",
      "4  0.147549  0.010035  0.887747  id04081\n"
     ]
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df['id'] = df_test['id']\n",
    "y_pred_df.rename(columns={0:'EAP',\n",
    "                          1:'HPL',\n",
    "                          2:'MWS'}, \n",
    "                 inplace=True)\n",
    "print(y_pred_df.head())\n",
    "y_pred_df.to_csv(\"conv_result.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ne4Wi9BZAtRh"
   },
   "source": [
    "# LSTM + CNN + Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dL4I7JZjw9v8"
   },
   "source": [
    "This model builds upon the previous architecture by utilizing pre-trained Glove word embeddings. The yelp project works with the vector of 100 dimensions, I have decided to use the one with 300 dimensions, because why not. The switch from 100D to 300D improved the accuracy slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LIfI90OPEkFt",
    "outputId": "73196bd4-06e7-4e2d-9fb2-0dacebe52bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt', encoding='utf-8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "#fn2.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVV-6NX0HaOS"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3U6TfsyLaF7"
   },
   "outputs": [],
   "source": [
    "model_glove = Sequential()\n",
    "model_glove.add(Embedding(vocabulary_size, 300, input_length=50, weights=[embedding_matrix], trainable=False))\n",
    "model_glove.add(Dropout(0.2))\n",
    "model_glove.add(Conv1D(64, 5, activation='relu'))\n",
    "model_glove.add(MaxPooling1D(pool_size=4))\n",
    "model_glove.add(LSTM(300))\n",
    "model_glove.add(Dense(3, activation='sigmoid'))\n",
    "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "VDc1wEGoLeA1",
    "outputId": "7230a4cb-8381-4c22-e159-3f90239bfb92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "294/294 [==============================] - 7s 20ms/step - loss: 0.6141 - accuracy: 0.4477 - val_loss: 0.5905 - val_accuracy: 0.4853\n",
      "Epoch 2/3\n",
      "294/294 [==============================] - 6s 19ms/step - loss: 0.5321 - accuracy: 0.5873 - val_loss: 0.5565 - val_accuracy: 0.5544\n",
      "Epoch 3/3\n",
      "294/294 [==============================] - 6s 19ms/step - loss: 0.4260 - accuracy: 0.6953 - val_loss: 0.5801 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x179231710>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_glove.fit(X_train, labels_train, validation_split=0.4, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "r3z17Wso7V-J",
    "outputId": "7641b532-e7c9-4340-c66e-eb8ac193b8d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.63      1600\n",
      "           1       0.65      0.33      0.44      1102\n",
      "           2       0.52      0.57      0.55      1214\n",
      "\n",
      "    accuracy                           0.56      3916\n",
      "   macro avg       0.58      0.54      0.54      3916\n",
      "weighted avg       0.58      0.56      0.55      3916\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1145</td>\n",
       "      <td>116</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>430</td>\n",
       "      <td>368</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439</td>\n",
       "      <td>79</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1    2\n",
       "author_label                \n",
       "0             1145  116  339\n",
       "1              430  368  304\n",
       "2              439   79  696"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_glove.predict(X_test)\n",
    "\n",
    "cr_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, cr_pred))\n",
    "\n",
    "pd.crosstab(y_test,cr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BMSX-lKK0Hy6"
   },
   "source": [
    "Looks like the more complex we go, the worse results we get.\n",
    "\n",
    "Edgar Allan Poe - 67% (1066/1600).\n",
    "H.P. Lovecraft - 56% (612/1102).\n",
    "Mary Wollstonecraft Shelley - 47% (565/1214)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "4FgIuqkB7hcS",
    "outputId": "61e4a582-871c-4132-8da5-15d8143d89c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "368/368 [==============================] - 7s 19ms/step - loss: 0.4642 - accuracy: 0.6591 - val_loss: 0.4606 - val_accuracy: 0.6632\n",
      "Epoch 2/3\n",
      "368/368 [==============================] - 7s 18ms/step - loss: 0.3871 - accuracy: 0.7326 - val_loss: 0.4385 - val_accuracy: 0.6821\n",
      "Epoch 3/3\n",
      "368/368 [==============================] - 7s 19ms/step - loss: 0.3241 - accuracy: 0.7808 - val_loss: 0.4637 - val_accuracy: 0.6768\n",
      "263/263 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "labels = keras.utils.to_categorical(df['author_label'], num_classes=3)\n",
    "\n",
    "model_glove.fit(data, labels, validation_split=0.4, epochs=3)\n",
    "\n",
    "y_pred = model_glove.predict(data_test)\n",
    "\n",
    "cr_pred = np.argmax(y_pred, axis=1) # gives a list of predicted values (picks the one with the highest probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAorYkio0CyU"
   },
   "source": [
    "Saving the file in the desired format for submission / uploading to the Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "vmYHEUblBSla",
    "outputId": "2984eca0-ed5a-4f0e-fe98-617120fe5e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        EAP       HPL       MWS       id\n",
      "0  0.198286  0.822722  0.030150  id02310\n",
      "1  0.398770  0.414429  0.105664  id24541\n",
      "2  0.110008  0.828182  0.061010  id00134\n",
      "3  0.286303  0.010103  0.709364  id27757\n",
      "4  0.545852  0.115983  0.305244  id04081\n"
     ]
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df['id'] = df_test['id']\n",
    "y_pred_df.rename(columns={0:'EAP',\n",
    "                          1:'HPL',\n",
    "                          2:'MWS'}, \n",
    "                 inplace=True)\n",
    "print(y_pred_df.head())\n",
    "y_pred_df.to_csv(\"glove_result.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text_classification JP.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
